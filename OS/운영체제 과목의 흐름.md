# 운영체제 과목의 흐름

운영체제 파트를 정리하며 운영체제란 과목이란 무얼 위해 배울까를 생각해보았다.

내가 느낀 운영체제 파트는 '개발자가 만든 프로그램을 사용자가 사용할 때, 
컴퓨터에서 일어나는 일련의 과정'을 공부하는 것이다.

사용자가 프로그램을 실행하면,
1. 사용자가 보조기억장치에 위치한 프로그램을 실행하면 
2. 프로그램은 주기억장치에 올라가 인스턴스화를 통해 프로세스가 되고  
3. 운영체제의 CPU 스케줄러에 따라 
4. CPU에서 프로세스를 처리한다.

<br>

## 소스코드에서 프로그램으로

개발자가 만든 소스코드 파일은 컴파일 과정을 거쳐 실행 가능한 파일로 변환된다.

우선 주석을 제거하고 헤더 파일을 병합하여 메크로로 치환하는 `전처리 과정`을 거친다.
그 후 `컴파일러`를 통해 오류를 처리하고 코드를 최적화해 `어셈블리어`로 변환된다.
다음으로 `어셈블러`를 통해 어셈블리어는 `목적 코드`로 변환되고, 
`링커`를 통해 라이브러리 함수 또는 다른 파일들과 목적 코드를 결합해 .exe나 .out 확장자를 가진 `실행 파일`이 만들어진다.

참고로 `링커`에서 결합되는 라이브러리는 정적 라이브러리, 동적 라이브러리로 두 가지 종류가 있는데,
정적 라이브러리는 프로그램 빌드 시, 라이브러리가 제공하는 모든 코드를 실행 파일에 넣는 방식이라 외부 의존도가 낮지만 메모리 효율성이 떨어진다.
동적 라이브러리는 프로그램 실행 시, 필요할 때만 DLL이란 함수 정보를 통해 참조하여 라이브러리를 사용하는 방식이다.

<br>

## 사용자가 프로그램을 실행하면

운영체제의 구조는 맨 위에 응용 프로그램이 있고 
그 아래에 `GUI 인터페이스`, `시스템 콜`, `커널` 순으로 운영체제가 존재하고
맨 아래 CPU, 메모리, I/O 디바이스 등을 칭하는 하드웨어가 위치한다.

운영체제를 한 마디로 설명하자면 `사용자가 컴퓨터를 쉽게 다루게 해주는 인터페이스`이다.

사용자는 `GUI 인터페이스`를 이용해 아이콘을 클릭해 원하는 프로그램을 실행한다.
이제 아래 `시스템 콜`을 이용하게 되는데, 시스템 콜은 `운영체제가 커널에 접근하기 위한 인터페이스`이다.
컴퓨터 자원에 대해 `유저 모드`, `커널 모드`란 두 가지 모드가 있는데, 유저 모드는 유저가 접근할 수 있는 제한적 모드이고
커널 모드는 모든 컴퓨터 자원에 접근할 수 있는 모드이다. 시스템 콜을 통해 유저 모드에서 커널 모드로 변환되어 프로그램을 실행할 수 있는 것이다.
우리는 아이콘을 더블 클릭해서 프로그램을 실행했는데, 클릭은 하나의 I/O 요청이고 이것은 `인터럽트`(여기선 트랩)를 발생시킨다.
`인터럽트`는 프로그램 실행 중 예기치 않은 상황이 발생할 때, 실행중인 작업을 잠시 중단하고 (CPU 잠깐 정지) 발생된 상황을 처리한 뒤 실행중인 작업으로 다시 복귀하는 것을 말한다.
시스템 콜을 통해 이 클릭이 올바른 I/O 요청인지 확인 후 유저 모드가 커널 모드로 변환되어 실행된다. 
좀 더 자세히는 인터럽트가 발생하면 커널의 인터럽트 종류마다 번호를 정하고 번호에 따라 처리해야되는 코드가 위치한 부분을 가르키고 있는 `인터럽트 벡터`로 이동한다.
그리고 발생한 인터럽트에 해당하는 `인터럽트 서비스 루틴(ISR, 인터럽트 핸들러 함수)`를 실행하고 다시 유저 모드로 변환된다.

시스템 콜 덕분에 컴퓨터 자원에 대한 직접 접근을 차단하고 프로그램을 다른 프로그램으로부터 보호할 수 있다.
또 시스템 콜은 인터페이스로 하나의 추상화 계층이기 때문에 낮은 단계 영역(데이터 베이스, 네트워크 등)을 신경 쓰지 않고 프로그램을 구현할 수 있다.
참고로 유저 모드와 커널 모드는 modebit란 플래그 변수를 참고해서 구분하는데, 유저 모드의 modebit은 1이고 커널 모드의 modebit은 0이다.

인터럽트는 하드웨어 인터럽트, 소프트웨어 인터럽트로 나뉘는데,
하드웨어 인터럽트는 외부 인터럽트로 키보드, 마우스 같은 I/O 장치에서 발생시키는 인터럽트를 말한다.
(컴퓨터 구조에서 설명할) 디바이스 컨트롤러가 CPU 인터럽트 라인을 세팅하고 인터럽트 발생을 통보하면 CPU는 하던 일을 멈추고 인터럽트를 처리한다.
예시로는 I/O 인터럽트, 전원 인터럽트, (컴퓨터 구조에서 설명할) 타이머 인터럽트가 있다.
소프트웨어 인터럽트는 내부 인터럽트로 0으로 나누기, 오버플로우 등의 오류에 해당하는 Exception 인터럽트 (트랩, trap)이 있고
open("a.txt") 같은 명령어가 들어왔을 때, 시스템 콜 호출을 위한 SVC 인터럽트가 있다.

이렇게 운영체제는 커널 함수를 제공하는것 뿐만 아니라
CPU 소유권을 어떤 프로세스에 할당할지 정하는 `CPU 스케줄링`과 
프로세스의 생성과 삭제, 자원의 할당과 반환을 관리하는 `프로세스 관리`
한정된 메모리를 어떤 프로세스에 얼만큼 할당해야 하는지 관리하는 `메모리 관리`,
디스크 파일을 어떤 방법으로 보관할지 관리하는 `디스크 파일 관리`,
그리고 I/O 디바이스와 컴퓨터 간에 데이터를 주고받는 것을 관리하는 `I/O 디바이스 관리`를 담당한다.

<br>

## 프로그램이 올라갈 메모리는

메모리 계층은 위에서부터 `레지스터`, `캐시`, `주기억장치`, `보조기억장치`가 있다.

`레지스터`는 CPU 안에 있는 매우 빠른 임시기억장치로 CPU는 자체적으로 데이터를 저장할 방법이 없기 때문에 레지스터를 거쳐 데이터를 전달한다.
`캐시`는 L1, L2, L3 캐시를 지칭한다.
`주기억장치`는 `RAM (Random Access Memory)`를 말한다. 하드디스크로부터 일정량의 데이터를 복사해서 임시 저장하고 필요할 시에 CPU에 빠르게 전달하는 역할을 한다.
`보조기억장치`는 HDD, SSD를 일컬어 말한다.
높은 계층일수록 속도가 빠르고 용량이 작지만 가격은 비싸다.
또 레지스터, 캐시, 주기억장치는 휘발성인 반면에 보조기억장치는 비휘발성인 특징을 갖고 있다.

두 번째의 `캐시 (cache)` 계층이 생소한데, 이는 데이터를 미리 복사해 놓는 임시 저장소이다.
빠른 장치와 느린 장치의 속도 차이에 의한 병목 현상을 줄이기 위한 메모리이다.
캐시에 원하는 데이터가 있을수도 없을수도 있다.
CPU의 제어장치가 캐시에서 원하는 데이터를 찾으면 이를 캐시 히트라 한다. 이때, 캐시에서 데이터를 제어장치를 통해 가져오는데 CPU 내부 버스를 기반으로 작동해서 빠르다.
반면 캐시에서 원하는 데이터가 없으면 캐시 미스라 한다. 이때, 메모리에서 데이터를 가져오는데 시스템 버스를 기반으로 작동해서 느리다.
캐시가 히트되기 위해선 메모리에서 캐시로 데이터를 미리 세팅해야하는데 이를 `캐시 매핑`이라 한다.
캐시 매핑에는 3가지 방법이 있는데 `메모리가 1~100`, `캐시가 1~10`이 있다는 예시로 설명하자면,
`직접 매핑`은 캐시 1에는 `메모리 1~10`, 캐시 2에는 `메모리 11~20`.. 식으로 매핑하는 것이다. 처리가 빠르지만 충돌 발생이 잦아 성능이 떨어진다.
`연관 매핑`은 순서를 일치시키지 않고 캐시 어디든 메모리를 매핑하는 것이다. 충돌은 적지만 모든 블록을 탐색해야해서 속도가 느리다.
`집합 연관 매핑`은 `캐시 1~5`에는 `메모리 1~50`을 무작위로 매핑시키는 것이다. 즉, 순서를 일치시키지만 집합을 둬서 매핑하여 검색이 더 효율적이다.

우리가 컴퓨터의 메모리를 사용할 땐, `캐시`, `주기억장치`, `보조기억장치`의 이용 가능한 메모리 자원을 함께 추상화하여
사용자들에게 매우 큰 메모리로 보이게 만드는 `가상 메모리 (virtual memory)`를 사용한다.
가상 메모리는 가상 주소와 실제 주소가 매핑되어있고 프로세스 정보가 들어있는 `페이지 테이블`로 관리되고,
속도 향상을 위해 메모리와 CPU 사이에 있는 메모리 주소 변환을 위한 캐시인 `TLB`를 사용한다.
CPU가 페이지 테이블 대신 TLB에 접근해 주소를 가져와 속도를 향상시킨다.
가상 메모리에 주어진 `가상 주소 (logical memory)`는 실제 메모리 주소인 `실제 주소 (physical memory)`로 변환해 사용해야하는데,
`MMU`란 메모리관리장치를 이용한다. MMU에는 `한계 레지스터 (limit register)`와 `재배치 레지스터 (relocation register)`가 존재하는데,
한계 레지스터에는 해당 프로세스 가상 주소값의 최대값, 즉 프로세스의 크기를 담고 있다.
그래서 MMU에 가상 주소가 들어오면 한계 레지스터 값을 넘어서는지 체크하고, 넘어서면 trap을 발생시킨다.
재배치 레지스터는 해당 프로세스의 물리적 메모리의 시작 주소를 담고 있어서 한계 레지스터를 통과한 가상 주소에 이 시작 주소로 더하면서 실제 주소로 변환된다.
이렇게 주소를 변환하며 사용하다가 프로세스 주소 공간에는 존재하지만 RAM에는 없는 데이터에 접근하는 경우가 발생한다.
이것을 `페이지 폴트 (page fault)`라 부른다. 참고로 `페이지 (page)`는 가상 메모리를 사용하는 최소 단위이고, `프레임 (frame)`은 실제 메모리를 사용하는 최소 단위이다.
페이지 폴트가 발생하면 메모리에서 사용하지 않는 영역을 하드디스크로 옮기고, 하드디스크의 일부분을 마치 메모리처럼 불러와 사용하는 `스와핑 (swapping)`이 일어난다.
위 과정은 먼저 가상 주소가 들어와 페이지 테이블에서 해당 페이지가 메모리에 있는지 valid bit을 통해 확인한다.
만약 valid bit가 0이라면 CPU에 페이지 폴트란 trap을 보내 운영체제 내부의 해당 ISR로 점프하게 된다.
해당 ISR은 backing store(디스크)를 탐색해 해당 프로세스의 페이지를 찾고 그 페이지를 비어있는 실제 메모리의 프레임에 할당한다.
그 후 페이지 테이블의 valid bit는 1로, 프레임 번호를 설정하며 업데이트하고 원래 실행하려던 작업을 진행한다.
이로써 사용자에게 마치 페이지 폴트가 일어나지 않은 것처럼 만드는 효과가 있다.

메모리가 한정되어있기 때문에 스와핑이 발생하는데, `페이지 교체 알고리즘`을 기준으로 스와핑이 많이 일어나지 않도록 설계된다.
성능 비교를 위한 상한 기준인 `오프라인 알고리즘`이 있는데, 먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘이다.
먼 미래에 어떤 페이지가 참조될지 모르기 때문에 상한 기준이 되는 알고리즘이다.
가장 먼저 온 페이지를 먼저 교체하는 `FIFO (First In First Out)`, 참조가 가장 오래된 페이지를 바꾸는 `LRU (Least Recently Used)`,
최근에 사용되지 않은 페이지를 교체하는 `NUR (Not Used Recently)`, 가장 참조 횟수가 적은 페이즐 교체하는 `LFU (Least Frequently Used)`가 있다.
그 중 NUR 알고리즘은 클락 알고리즘이라고 불리는데, 최근에 참조되지 않음을 의미하는 `0 비트`, 최근에 참조된 `1 비트`를 두고
시계 방향으로 돌면서 0 비트를 찾은 순간 해당 프로세스를 교체하며 해당 부분을 1 비트로 바꾸는 알고리즘이다.

메모리에 페이지 폴트율이 높은 것을 `스레싱 (thrasing)`이라 부르는데, 이는 심각한 성능 저하를 일으킨다.
스레싱은 메모리에 프로세스가 동시에 올라가면 스와핑이 많이 발생한다.
페이지 폴트가 자주 일어나면 CPU 이용률이 낮아지는데, 이 때 운영체제는 CPU가 한가하다고 생각해 가용성을 높이기 위해
더 많은 프로세스를 메모리에 올리게 된다. 이 과정으로 악순환이 반복된다.
스레싱을 해결하기 위해선 메모리를 늘리거나 HDD를 SSD로 교체하는 방법이 있다.
또 프로세스 과거 사용 이력인 지역성을 통해 결정된 페이지 집합을 만들어서 미리 메모리에 로드하는 `작업 세트 (working set)`을 사용할 수 있다.
작업 세트로 페이지 탐색에 필요한 비용과 스와핑을 줄일 수 있다.
그리고 페이지 폴트 빈도의 상한선과 하한선을 정해 빈도가 상한선에 도달하면 프레임을 늘리고, 하한선에 도달하면 프레임을 줄이는 `PFF (Page Fault Frequency)`를 사용할 수 있다.

메모리를 프로그램에 할당할 때는 시작 메모리 위치, 그리고 메모리의 할당 크기를 기반으로 할당하게 된다.
메모리 할당 방식은 `연속 할당`과 `불연속 할당` 방식이 있다.
먼저 연속 할당에는 `고정 분할 방식`과 `가변 분할 방식`이 있다.
고정 분할 방식은 물리적 메모리를 주어진 개수만큼 영구적인 분할로 미리 나누어 놓고 각 분할에 하나의 프로세스를 적재해 실행시키는 방식이다.
실행 가능한 프로그램의 크기와 개수가 분할에 따라 고정되어 융통성이 떨어진다는 단점이 있다.
또 메모리를 나눈 크기보다 프로그램이 작아 이후에 들어가지 못하는 공간이 발생하는 `내부 단편화`와
메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 공간이 발생하는 `외부 단편화`가 발생할 가능성이 있다.
고정 분할 방식은 어차피 하나의 분할에 하나의 프로그램이 들어가므로 사실 내부 단편화는 메모리 낭비로 본다.
가변 분할 방식은 메모리에 적재되는 프로그램의 크기에 따라 분할의 크기와 개수가 동적으로 변하는 방식이다.
여기서 메모리를 할당할 땐, `최초 적합`, `최적 적합`, `최악 적합`으로 3가지 방식 중 정해서 사용하는데,
최초 적합은 위나 아래에서 시작해 홀을 찾으면 바로 할당해서 시간적 측면에서 효율적이다.
최적 적합은 할당할 프로세스 크기 이상인 공간 중 가장 작은 홀에 할당해서 공간적 측면에서 효율적이다.
최악 적합은 할당할 프로세스 크기와 가장 차이가 많이 나는 홀에 할당하는 방식이다.
최적 적합과 최악 적합 방식은 모든 홀의 크기를 탐색해야 하기 때문에 시간 효율적인 측면에서 최초 적합보다는 떨어진다.
가변 분할 방식은 내부 단편화는 발생하지 않고 외부 단편화는 발생할 수 있다. 내부 단편화가 발생하지 않는 이유는 `메모리 컴펙션`이라고
프로세스가 종료된 자리에 생기는 홀을 없애기 위해 적재된 프로세스를 한 쪽으로 모는 작업을 수행하기 때문이다. 다만 메모리 컴펙션은 오버헤드가 큰 작업이다.
다음으로 불연속 할당에는 `페이징 (paging)`과 `세그멘테이션 (segmentation)` 방식이 있다.
페이징은 메모리를 동일한 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스를 할당하는 방식이다.
홀의 크기가 균일하지 않은 문제점은 없지만 주소 변환이 복잡해진다.
페이지의 크기가 프레임의 크기와 같기 때문에 외부 단편화는 발생하지 않는다.
하지만 프로세스의 마지막에 위치한 페이지에는 내부 단편화가 발생할 수 있다. 만일 크기 200씩 페이지를 나눴는데, 마지막 페이지는 150인 경우이다.
세그멘테이션은 프로세스를 논리적 내용을 기반으로 나눠서 메모리에 배치하는 방식이다. 프로세스의 코드 영역과 데이터 영역으로 나누거나
코드 내 작은 함수를 세그먼트로 나눌 수 있다. 세그먼트의 크기가 동일하지 않으므로 홀의 크기 또한 동일하지 않게 된다.
세그먼트는 `세그먼트 테이블`을 바탕으로 메모리에 할당된다. 시작 주소인 base와 크기인 limit을 바탕으로 메모리 주소를 찾을 수 있다.
세그멘테이션은 내부 단편화는 발생하지 않지만 외부 단편화는 발생한다. 메모리에 세그먼트가 나가고 들어오고 반복하면서 상주한 세그먼트 사이에
빈틈이 생기는데 이 빈틈보다 큰 세그먼트는 들어갈 수 없기 때문이다.

<br>

## 프로그램은 프로세스로

위의 메모리 할당 방식에 따라 프로그램은 메모리를 할당받아 인스턴스화되면서 `프로세스 (process)`가 된다.

프로세스의 메모리 구조는 높은 주소 영역부터 `스택`, `힙`, `데이터`, `텍스트` 영역이 있다.
이 중 스택과 힙 영역은 런타임 단계에서 메모리를 할당받는 `동적 할당`이 되고, 데이터와 코드 영역은 컴파일 단계에서 메모리를 할당 받는 `정적 할당`이 된다.
`스택 영역`은 지역 변수, 매개 변수, 실행되는 함수에 의해 늘어나거나 줄어드는 메모리 영역이다.
함수가 호출될 때마다 호출될 때의 환경 등 정보가 스택에 계속해서 저장된다.
그래서 재귀 함수가 호출될 때, 새로운 스택 프레임이 계속 사용되기 때문에 함수 내의 변수 집합이 다른 인스턴스 변수를 방해하지 않는 것이다.
`힙 영역`은 동적으로 할당되는 변수들을 담는 메모리 영역이다. 동적으로 관리되는 자료 구조의 경우 힙 영역을 사용한다.
`데이터 영역`은 `BSS segment`와 `Data segment`로 나뉘는데, BSS segment에는 초기화 안한 전역 변수가, Data segment에는 초기화한 전역 변수가 할당된다.
`텍스트 영역`은 함수 코드, 제어문, 상수 등이 들어간다.

이렇게 만들어진 각 프로세스는 상태를 갖는데,
먼저 프로세스가 생성된 상태인 `생성 상태 (create)`이 있다. 이때 다음에 설명할 PCB가 할당된다.
`fork()` 함수를 통해선 부모 프로세스의 주소 공간을 그대로 복사하여 자식 프로세스를 생성하고
`exec()` 함수를 통새너 새롭게 프로세스를 생성한다.
그 후 `대기 상태 (ready)`가 되는데, CPU 스케줄러로부터 CPU 소유권이 넘어오기를 기다리는 상태이다.
이때 메모리 공간이 충분하다면 메모리를 할당받고 아니라면 대기한다.
대기 상태에서 메모리가 부족하면 `대기 중단 (ready suspended)` 상태가 되고,
CPU 스케줄링을 통해 CPU 소유권을 받으면 `실행 (running)` 상태가 된다. 실행 상태는 CPU 소유권과 메모리를
할당받고 인스트럭션을 수행하며 이를 CPU burst라고도 부른다.
실행 상태 중에 어떤 이벤트(인터럽트)가 발생하면 `중단 (blocked)` 상태가 되고,
중단 상태에서 프로세스가 다시 실행되려 했지만 메모리가 부족하면 `일시 중단 (blocked suspended)` 상태가 된다.
실행 중 프로세스가 종료되면 `종료 (terminated)` 상태가 되는데, CPU 소유권과 메모리를 모두 놓고 가게 된다.
종료 방식은 정상적으로 종료될 수도 있지만, 
자식 프로세스에 할당된 자원의 한계치를 넘은 경우, 부모 프로세스가 종료된 경우, 사용자가 명령어로 종료한 경우로 비정상적 종료가 될 수도 있다.

프로세스가 생성되면 `PCB (Process Control Block)`이란 프로세스 제어 블록이 생성된다.
PCB는 운영체제에서 프로세스에 대한 메타데이터를 저장한 데이터이고 일반 사용자가 접근하지 못하도록 커널 스택 맨 앞에서 관리된다.
PCB의 구조는,
- 프로세스 스케줄링 상태: '대기', '일시 중단' 등 프로세스가 CPU 소유권을 얻은 이후의 상태
- 프로세스 ID: 프로세스 ID, 해당 프로세스의 자식 프로세스 ID
- 프로세스 권한: 컴퓨터 자원 or I/O 디바이스에 대한 권한 정보
- 프로그램 카운터: 프로세스에서 실행되어야할 다음 명령어 주소에 대한 포인터
- CPU 레지스터: 프로세스를 실행하기 위해 저장해야할 레지스터 정보
- CPU 스케줄링 정보: CPU 스케줄러에 의해 중단된 시간 등에 대한 정보
- I/O 상태의 정보: 프로세스에 할당된 I/O 디바이스 목록

등으로 구성된다.

싱글 코어 기준, 어떤 시점에서 CPU에서 실행되고 있는 프로세스는 단 하나이다.
그래서 운영체제는 `컨텍스트 스위칭 (context switching)`을 통해 여러 프로세스가 동시에 구동되는것 같은 효과를 만든다.
컨텍스트 스위칭은 `PCB를 기반으로 프로세스의 상태를 저장하고 로드시키는 과정`이다.
한 프로세스의 할당된 시간이 끝나는 경우나 인터럽트가 발생할 때 컨텍스트 스위칭 과정이 일어난다.
실행중이던 프로세스 A가 인터럽트에 의해 중단되면, PCB(A)에 프로세스 A의 상태가 저장된다.
그러면서 PCB(B)로 프로세스 B를 로드해 실행하는 것이다.
컨텍스트 스위칭의 비용으로는 `유휴 시간 (idle time)`과 `캐시 미스`가 있다.
유휴 시간은 각 프로세스의 실행이 중단된 동안의 시간이고,
캐시 미스는 컨텍스트 스위칭이 발생할 때, 프로세스가 가지고 있는 메모리 주소가 그대로 있으면 
잘못된 주소 변환이 생기므로 캐시클리어 과정이 일어나고 이 때문에 캐시 미스가 발생한다.

여러 개의 프로세스를 통해 동시에 두 가지 이상의 일을 수행하는 것을 `멀티프로세싱`이라 한다.
멀티프로세싱으로 하나의 일을 병렬로 처리할 수 있으며,
프로세스 일부에 문제가 생기더라도 다른 프로세스를 이용할 수 있어 신뢰성이 높다.
대표적인 멀티프로세싱의 예시는 웹 브라우저이다.
`브라우저 프로세스`는 주소 표시줄, 북마크 막대, 뒤로가기 버튼 등을 담당하고 네트워크 요청이나 파일 접근 같은 권한을 담당한다.
`렌더러 프로세스`는 웹사이트 보이는 부분의 모든 것을 담당한다.
`플러그인 프로세스`는 사용하는 플러그인을 제어한다.
그리고 `GPU 프로세스`는 GPU를 이용해 화면을 그리는 부분을 제어한다.
멀티프로세스는 프로세스끼리 데이터를 주고받고 공유 데이터를 관리하는 메커니즘인 `IPC (Inter Process Communitcation`)이 가능하다.
`공유 메모리 (shared memroy)`는 동일한 메모리 블럭을 여러 프로세스가 접근해서 통신하는 것이다.
원래 각 프로세스는 다른 프로세스의 메모리에 접근할 수 없지만, 여러 프로세스가 하나의 메모리를 공유할 수 있다.
메모리 자체를 공유하기 때문에 불필요한 데이터 복사 오버헤드가 없어서 `가장 빠르다`.
하지만 같은 메모리 영역을 여러 프로세스가 공유하기 때문에 `동기화가 필요하다`.
`파일`은 디스크에 저장된 데이터 또는 파일 서버에서 제공한 데이터를 기반으로 프로세스 간에 통신을 하는 방법이다.
`소켓`은 동일한 컴퓨터의 다른 프로세스나 네트워크의 다른 컴퓨터로 네트워크 인터페이스를 통해 전송하는 데이터이고 TCP와 UDP가 있다.
`익명 파이프 (unnamed piped)`는 프로세스 간에 FIFO 방식으로 읽히는 임시 공간인 파이프를 기준으로 데이터를 주고 받는 방식이다.
단방향 읽기 전용, 쓰기 전용 파이프를 만들어 동작하고 부모-자식 프로세스 간에만 사용할 수 있다.
`명명된 파이프 (named piped)`는 파이프 서버와 하나 이상의 파이프 클라이언트 간의 통신을 위한 명명된 단방향, 양방향 파이프를 말한다.
여러 파이프를 동시에 사용할 수 있고 하나의 인스턴스를 열거나 여러 개의 인스턴스를 기반으로 통신한다.
같은 컴퓨터의 프로세스끼리, 다른 네트워크상의 컴퓨터와 모두 통신할 수 있고 보통 서버용 파이프와 클라이언트 파이프로 구분해서 동작한다.
`메세지 큐`는 메세지를 큐(queue) 데이터 구조 형태로 관리하는 방식이다.
커널에서 전역적으로 관리되며 다른 IPC 방식에 비해 사용법이 간단하다.

프로세스 내에는 프로세스의 실행 가능한 가장 작은 단위인 `스레드`가 있다.
스레드는 프로세스의 코드, 데이터, 힙 영역을 서로 공유하고, `스택 영역`은 각각 생성된다.
프로세스처럼 스레드도 `멀티스레딩`이 가능한데, 프로세스 내 작업을 여러 개의 스레드로 처리하는 기법이다.
멀티스레딩은 스레드끼리는 서로 자원을 공유하기 때문에 효율성이 높다.
또 한 스레드가 중단되어도 다른 스레드는 실행 상태일 수 있기 때문에 동시성에 강점이 있다.
하지만 한 스레드에 문제가 생기면 다른 스레드에도 영향을 끼쳐 해당 프로세스에 악영향을 줄 수 있다.
멀티스레딩의 예시로는 웹 브라우저의 `렌더러 프로세스`가 있는데, 메인 스레드, 워커 스레드, 컴포지터 스레드, 레스터 스레드로 이루어진다.

앞에서 설명한 프로세스, 스레드가 함께 접근할 수 있는 자원이나 변수인 `공유 자원`이 있다.
공유 자원에는 모니터, 프린터, 메모리, 파일, 데이터 등이 있다.
이 공유 자원을 두 개 이상의 프로세스가 동시에 읽거나 쓰는 상황을 `경쟁 상태 (race condition)`이라 한다.
이 경쟁 상태에서 공유 자원 중 접근 순서 등에 의해 결과가 달라지는 코드 영역을 `임계 영역 (critical section)`이라 한다.
임계 영역 문제를 해결하기 위한 방법으로는 `뮤텍스`, `세마포어`, 그리고 `모니터`가 있다.
위 방법들은 한 프로세스가 임계 영역에 들어갔을 때, 다른 프로세스는 들어갈 수 없는 `상호 배제 (mutual exclustion)`,
특정 프로세스가 영원히 임계 영역에 들어가지 못하면 안되서 임계 여역에 제한을 두는 `한정 대기 (bounded waiting)`,
그리고 임계 영역을 아무도 사용하지 않으면 외부의 어떤 프로세스라도 들어갈 수 있고 이때 서로 접근을 방해하지 않는 `융통성 (progress)`의 조건들을 만족한다.
`뮤텍스 (mutex)`는 프로세스나 스레드가 공유 자원을 `lock()`을 통해 잠금 설정하고, 사용한 후에는 `unlock()`을 통해 잠금 해제하는 객체이다.
뮤텍스는 잠금 또는 잠금 해제라는 상태만을 가진다.
`세마포어 (semaphore)`는 일반화된 뮤텍스로 간단한 정수값과 wait/signal 함수로 공유 자원에 대한 접근을 처리한다.
`wait 함수 (P 함수)`는 자신의 차례가 올 때까지 기다리는 함수이고 프로세스나 스레드가 공유 자원에 접근할 때 호출된다.
`signal 함수 (V 함수)`는 다음 프로세스로 순서를 넘겨주는 함수이고 프로세스나 스레드가 공유 자원을 해제했을 때 호출된다.
세마포어의 특징으로는 조건 변수가 없고, 한 프로세스나 스레드가 세마포어를 수정할 때, 다른 프로세스나 스레드가 동시에 수정할 수 없다.
세마포어의 함수를 좀 더 자세히 알아보면,
`Semaphore(n)`은 현재 사용 가능한 자원의 수인 전역 변수 RS를 n으로 초기화한다.
`P()`는 잠금을 수행하는 코드이다. RS > 0 이면, 즉 사용 가능한 자원이 있으면, RS의 값을 1 감소시키고 임계 영역에 진입한다.
RS <= 0 이면, RS가 0보다 커질 때까지 block() 시킨다.
`V()`는 잠금 해제와 동시에 동기화를 함께 진행하는 코드이다.
RS의 값을 1 증가시키며 세마포어에서 기다리는 다른 프로세스에게 wake_up() 신호를 보내 임계 영역에 진입해도 좋다고 알린다.
세마포어의 종류로는 `바이너리 세마포어`, `카운팅 세마포어`가 있다.
`바이너리 세마포어`는 0과 1의 두 가지 값만 가질 수 있는 세마포어이다.
초기화 값이 1이라 사용 가능한 자원 수가 하나이기 때문에 공유 자원에 한 프로세스나 스레드가 진입하면 이후 들어갈 수 없다.
그래서 바이너리 세마포어는 상호배제를 위해 사용된다.
뮤텍스와 유사하지만 뮤텍스는 잠금 메커니즘이고 세마포어는 신호 메커니즘인 차이점이 있다.
`카운팅 세마포어`는 여러 자원에 대한 접근을 제어하는데 사용된다. 그래서 초기화 값이 1 이상이고, 여러 개의 프로세스가 임계 영역에 접근할 수 있다.
`모니터`는 공유 자원을 숨기고 해당 접근에 대한 인터페이스만 제공해 공유 자원에 안전하게 접근할 수 있도록 한다.
모니터는 `모니터 큐`를 통해 공유 자원에 대한 작업들을 순차적으로 처리하고 프로세스에는 결과만 알려준다. 큐를 사용하기 때문에 상호배제가 보장된다.

이렇게 여러 프로세스가 공유 자원을 함께 사용하다보면, 
두 개 이상의 프로세스들이 서로 가진 자원을 기다리며 중단된 상태인 `교착 상태 (데드락, dead lock)`에 빠질 수 있다.
데드락의 원인으로는 `상점비순`이 있다.
한 프로세스가 자원을 독점하고 다른 프로세스들은 접근이 불가한 `상호 배제`,
자원을 가진 프로세스가 다른 자원을 기다릴 때, 가지고 있는 자원을 놓지 않는 `점유 대기`,
프로세스가 자원을 가지고 있을 때, 자원을 스스로 내려놓는 것이지 빼앗기지 않는 `비선점`,
그리고 서로 기다리는 자원에 대해 사이클이 형성되는 `순환 대기`가 있다.
데드락의 해결 방법으로는 `예방`, `회피`, `탐지 및 복구`, 그리고 `무시`가 있다.
`예방`은 데드락의 원인이 되는 상점비순 중 하나를 부정하는 것이다.
`상호 배제 부정`은 읽기 전용 파일과 같은 고유 자원을 사용해 이루어진다.
`점유 대기 부정`은 만약 프로세스 대기를 없애기 위해 실행되기 전 필요한 모든 자원을 할당하면 자원 낭비가 되고,
자원을 점유하지 않았을 때만 다른 자원을 요청할 수 있도록 하면 기아 상태가 될 수 있다.
`비선점 부정`은 모든 자원에 대한 선점을 허용해서 이루어진다. 프로세스가 할당받을 수 없는 자원을 요청했을 경우,
기존에 가지고 있던 자원을 모두 반납하고 새 자원과 이전 자원을 얻기 위해 대기해 자원 낭비가 된다.
`순환 대기 부정`은 자원에 고유 번호를 할당해서 번호 순서대로 자원을 할당하면 되는데 이 역시 자원 낭비이다.
그래서 데드락 원인 중 하나를 제거하는 것은 자원 낭비가 심한 방법이다.
`회피`는 교착 상태에 빠질 수 있는 가능성을 OS가 검사한 후, 가능성이 없을 경우에만 자원을 할당하는 방법이다.
이때 `은행원 알고리즘`이 사용되는데, 총 자원의 양과 현재 할당한 자원의 양을 기준으로 안정 혹은 불안정 상태로 나누고
안정 상태로 가도록 자원을 할당하는 알고리즘이다. 은행원 알고리즘은 복잡하고 가지고 있어야 할 최대 자원을 미리 알아야 해서 오버헤드가 큰 방법이다.
`탐지 및 복구`는 OS가 자원을 달라는대로 주면서 주기적으로 데드락(사이클)이 없는지 확인하는 방법이다.
데드락이 발생하면 이전 상태로 복구하고, 관련된 프로세스나 스레드 하나를 죽이고 죽인 놈이 갖고 있던 자원을 던져줘야한다.
데드락 확인에 오버헤드가 큰 방법이다.
`무시`는 데드락이 발생하면 사용자가 직접 종료하게 하는 방법이다.
데드락은 매우 드물게 일어나고 상점비순을 모두 만족했다 해서 데드락에 걸리는 것도 아니다.
반면 예방과 회피 기법을 넣으면 처리하는 비용이 커서 많은 OS가 무시 기법을 사용한다.

<br>

## 프로세스는 CPU 스케줄링 알고리즘에 따라 CPU 소유권을 얻게 되는데

프로그램이 메모리에 올라가 인스턴스화되어 프로세스가 되면, OS는 이 프로세스를 `CPU 스케줄링 알고리즘`에 따라 CPU 소유권을 넘겨준다.
또 컨텍스트 스위칭이 일어날 때, 이 알고리즘에 따라 어떤 프로세스로 교체할지 결정한다.
`CPU 스케줄링 알고리즘`은 `비선점형`과 `선점형`으로 나뉘는데,
`비선점형 (non-preemptive)`는 프로세스가 스스로 CPU 소유권을 포기하는 방식이다. 즉, 강제로 프로세스를 중지하지 않는다.
따라서 컨텍스트 스위칭으로 인한 부하가 적다.
`선점형 (preemptive)`는 실행중인 프로세스를 알고리즘에 의해 중단시키고 강제로 다른 프로세스에 CPU 소유권을 넘겨주는 방식이다.
현대 운영체제가 사용하는 방식이 이 선점형이다.
우선, 비선점형 알고리즘에는 `FCFS`, `SJF`, `우선순위`가 있다.
`FCFS (First Come First Served)`는 가장 먼저 온 것을 가장 먼저 처리하는 알고리즘이다.
이런 특성 때문에 준비 큐에서 오래 기다리는 현상(convoy effect)가 발생하는 단점이 있다.
`SJF (Shortest Job First)`는 실행 시간이 가장 짧은 프로세스를 가장 먼저 실행하는 알고리즘이다.
실행 시간은 과거 실행했던 시간을 토대로 추측해서 사용하고 평균 대기 시간이 가장 짧다.
하지만 실행 시간이 긴 프로세스가 실행되지 않는 현상(starvation)이 발생한다.
`우선순위`는 SJF 알고리즘의 starvation 현상을 해결하기 위해
오래된 작업일수록 우선순위를 높이는 방법(align, 노화 기법 aging)을 사용해 보완한 알고리즘이다.
기다리는 시간이 길어짐에 따라 실행 시간이 긴 프로세스도 우선순위가 높아져 CPU 소유권을 얻을 수 있다.
참고로 우선순위는 비선점형뿐만 아니라 선점형으로도 만들 수 있다.
다음으로 선점형 알고리즘에는 `SRF`, `라운드 로빈`, `다단계 큐`가 있다.
`SRF (Shortest Remaining Time First)`는 프로세스 실행 중간에 실행 시간이 더 짧은 프로세스가 들어오면
중지하고 해당 프로세스를 수행하는 알고리즘이다. SJF와 같이 실행 시간이 짧은 프로세스가 계속해 들어오면,
실행 시간이 긴 프로세스는 순번이 밀려 실행되지 않아 starvation이 발생한다.
`라운드 로빈 (Round Robin)`은 각 프로세스에게 CPU를 사용할 수 있는 최대 시간(time quantum)을 주고
타임퀀텀안에 끝나지 않으면 다시 준비 큐의 뒤로 가는 알고리즘이다. 이 타임퀀텀이 너무 크면 FCFS가 되고,
너무 짧으면 컨텍스트 스위칭이 잦아져 오버헤드가 커진다. 일반적으로는 전체 작업시간은 길어지지만 평균 응답시간은 짧아진다.
라운드 로빈은 현대 운영체제가 사용하는 방식이다.
`다단계 큐`는 우선순위에 따른 준비 큐를 여러 개 사용하고, 큐마다 다른 스케줄링 알고리즘을 적용한 방식이다.
예를 들어, foreground 처럼 반응 속도가 빨라야 하는 프로세스는 타임퀀텀을 짧게 한 준비 큐를 사용하고, 
background 처럼 사용자와 상호작용이 없는 프로세스는 타임퀀텀을 길게 해 FCFS 같은 준비 큐를 사용한다.
하지만 우선순위가 높은 큐에 작업이 계속 들어오면 우선순위가 낮은 큐의 작업이 처리되지 않는 단점이 있다.
또 큐 간의 프로세스 이동이 안되서 스케줄링 부담은 적지만 유연성이 떨어진다.
다단계 큐는 우선순위가 낮은 준비 큐에 불리한데, 이것을 해결하기 위해 `다단계 피드백 큐`가 등장했다.
다단계 피드백 큐는 다단계 큐와 유사하지만 CPU를 사용한 프로세스는 우선순위가 낮아진다.
그래서 상위 큐의 작업들이 우선순위가 계속 낮아져 언젠가 하위 큐의 작업들과 우선순위가 같아지게 된다.
또 큐 간의 이동이 가능해서 노화 기법(aging)으로 오래 기다린 작업을 상위 큐로 격상할 수 있다.
하위 큐로 갈수록 타임퀀텀을 길게 해서 실행시간이 긴 프로세스도 모두 실행이 가능하다.

<br>

## 스케줄링 알고리즘에 따라 CPU는 프로세스를 처리하는데, 컴퓨터 구조에서 CPU는

`CPU (Central Processing Unit)`는 `산술논리연산장치`, `제어장치`, 그리고 `레지스터`로 이루어진다.
`산술논리연산장치 (ALU, Arithmetric Logic Unit)`은 산술 연산과 논리 연산을 계산하는 디지털 회로이다.
`제어장치`는 프로세스 조작을 지시하는 CPU 부품으로, 입출력장치 간 통신을 제어하고,
명령어들을 읽고 해석하고, 데이터 처리를 위한 순서를 결정한다.
`레지스터`는 CPU 안에 있는 매우 빠른 임시 기억장치이다.
CPU는 자체적으로 데이터를 저장할 방법이 없어 레지스터를 거쳐 데이터를 전달한다.
CPU가 작동하는 방식은 먼저 제어장치가 계산할 값을 메모리와 레지스터로 로드한다.
그 후 레지스터에 있는 값을 산술논리연산장치에게 계산을 시킨다.
그 계산된 값을 레지스터에서 메모리로 저장한다.
이처럼 CPU는 인터럽트에 의해 단순히 메모리에 존재하는 명령어를 해석해서 실행하는 일꾼이다.

컴퓨터 부품 중 CPU 이외에도 `DMA 컨트롤러`, `타이머`, `디바이스 컨트롤러`가 있다.
`DMA 컨트롤러`는 I/O 디바이스가 메모리에 직접 접근할 수 있도록 하는 하드웨어 장치이다.
CPU에 많은 인터럽트 요청이 들어오기 때문에 CPU의 부하를 막아주며 CPU의 일을 대신 부담하는 보조 일꾼이다.
또 하나의 작업을 CPU와 DMA 컨트롤러 동시에 하는 것을 방지한다.
`타이머`는 특정 프로그램에 시간 제한을 다는 역할을 한다. 시간이 많이 걸리는 프로그램에 제한을 걸기 위해 존재한다.
`디바이스 컨트롤러`는 컴퓨터와 연결되어 있는 I/O 디바이스의 작은 CPU이다. 
각 디바이스 컨트롤러 옆엔 `로컬 버퍼`가 달려있는데, 각 디바이스에서 데이터를 임시로 저장하기 위한 작은 메모리이다.